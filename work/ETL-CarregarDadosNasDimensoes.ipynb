{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import das bibliotecas\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "from os.path import isfile, isdir, join\n",
    "import pm4py\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars file:///home/jovyan/jdbc/postgresql-42.2.17.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = \"jdbc:postgresql://postgres:5432/dbinovacnj\"\n",
    "db_name = \"dbinovacnj\"\n",
    "db_user = \"inovacnj\"\n",
    "db_pass = \"inovacnj@admin\"\n",
    "db_driver = \"org.postgresql.Driver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialização do spark\n",
    "conf = SparkConf() \\\n",
    "        .setMaster(\"local[2]\") \\\n",
    "        .setAppName(\"LendoDB\") \\\n",
    "        .set(\"spark.executor.memory\", \"4g\") \\\n",
    "        .set(\"spark.driver.memory\", \"4g\") \\\n",
    "        .set(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "        .set(\"spark.ui.enabled\", \"true\") \\\n",
    "        .set(\"spark.sql.shuffle.partitions\" , \"800\") \\\n",
    "        .set(\"spark.sql.execution.arrow.pyspark.enabled\" , \"false\") \\\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo o schema dos dados\n",
    "schema = StructType([\n",
    "    StructField(\"dadosBasicos\", StructType([\n",
    "        StructField(\"assunto\", ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"assuntoLocal\", StructType([\n",
    "                    StructField(\"codigoAssunto\", LongType(), True),\n",
    "                    StructField(\"codigoPaiNacional\", LongType(), True),\n",
    "                    StructField(\"descricao\", StringType(), True)\n",
    "                ]), True),\n",
    "                StructField(\"codigoNacional\", LongType(), True),\n",
    "                StructField(\"principal\", BooleanType(), True)\n",
    "            ]),\n",
    "        ), True),\n",
    "        StructField('classeProcessual', LongType(), True),\n",
    "        StructField('codigoLocalidade', StringType(), True),\n",
    "        StructField('competencia', StringType(), True),\n",
    "        StructField('dataAjuizamento', StringType(), True),\n",
    "        StructField('dscSistema', StringType(), True),\n",
    "        StructField('nivelSigilo', LongType(), True),\n",
    "        StructField('numero', StringType(), True),\n",
    "        StructField(\"orgaoJulgador\", StructType([\n",
    "            StructField(\"codigoMunicipioIBGE\", LongType(), True),\n",
    "            StructField(\"codigoOrgao\", StringType(), True),\n",
    "            StructField(\"instancia\", StringType(), True),\n",
    "            StructField(\"nomeOrgao\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField('procEl', LongType(), True),\n",
    "        StructField(\"tamanhoProcesso\", StringType(), True),\n",
    "        StructField(\"totalAssuntos\", LongType(), True),\n",
    "        StructField(\"valorCausa\", StringType(), True)       \n",
    "    ]), True),\n",
    "    StructField(\"grau\", StringType(), True),\n",
    "    StructField(\"millisInsercao\", LongType(), True),\n",
    "    StructField(\"movimento\", ArrayType(     \n",
    "        StructType([\n",
    "            StructField(\"complementoNacional\", ArrayType(\n",
    "                StructType([\n",
    "                    StructField(\"codComplemento\", LongType(), True),\n",
    "                    StructField(\"codComplementoTabelado\", LongType(), True),\n",
    "                    StructField(\"descricaoComplemento\", StringType(), True),\n",
    "                ])\n",
    "            ), True),\n",
    "            StructField(\"dataHora\", StringType(), True),\n",
    "            StructField(\"idDocumentoVinculado\", ArrayType(\n",
    "                StringType(),\n",
    "            ), True),\n",
    "            StructField(\"identificadorMovimento\", StringType(), True),\n",
    "            StructField(\"movimentoLocal\", StructType([\n",
    "                StructField('codigoMovimento', LongType(), True),\n",
    "                StructField('codigoPaiNacional', LongType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"movimentoNacional\", StructType([\n",
    "                StructField('codigoNacional', LongType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"nivelSigilo\", StringType(), True),\n",
    "            StructField(\"orgaoJulgador\", StructType([\n",
    "                StructField(\"codigoMunicipioIBGE\", LongType(), True),\n",
    "                StructField(\"codigoOrgao\", StringType(), True),\n",
    "                StructField(\"instancia\", StringType(), True),\n",
    "                StructField(\"nomeOrgao\", StringType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"tipoDecisao\", StringType(), True),\n",
    "            StructField(\"tipoResponsavelMovimento\", StringType(), True)\n",
    "        ]),\n",
    "    ), True),\n",
    "    StructField(\"siglaTribunal\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega do dataframe de classes\n",
    "df_classes = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/sgt_classes.csv\")\n",
    "\n",
    "df_classes.createOrReplaceTempView(\"classes\")\n",
    "   \n",
    "df_qry_classes = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"codigo AS cod,\" + \n",
    "    \"descricao,\" + \n",
    "    \"sigla,\" + \n",
    "    \"cod_pai AS codpai \" +    \n",
    "    \"FROM classes \"\n",
    ")\n",
    "\n",
    "# df_qry_classes.write \\\n",
    "#     .mode(\"overwrite\") \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "#     .option(\"dbtable\", \"inovacnj.classe\") \\\n",
    "#     .save()\n",
    "\n",
    "print(\"tabela inovacnj.classe criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega do dataframe de assuntos\n",
    "df_assuntos = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/sgt_assuntos.csv\")\n",
    "\n",
    "df_assuntos.createOrReplaceTempView(\"assuntos\")\n",
    "   \n",
    "df_qry_assuntos = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"codigo AS cod,\" + \n",
    "    \"descricao,\" + \n",
    "    \"cod_pai AS codpai \" +    \n",
    "    \"FROM assuntos \"\n",
    ")\n",
    "\n",
    "# df_qry_assuntos.write \\\n",
    "#     .mode(\"overwrite\") \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "#     .option(\"dbtable\", \"inovacnj.assunto\") \\\n",
    "#     .save()\n",
    "\n",
    "print(\"tabela inovacnj.assunto criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega o dataframe de movimentos\n",
    "df_movimentos = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/sgt_movimentos.csv\")\n",
    "\n",
    "# cria uma view temporaria dos movimentos\n",
    "df_movimentos.createOrReplaceTempView(\"movimentos\")\n",
    "\n",
    "# carrega o dataframe de movimentos nacionais (com nossa classificacao de fases e natureza)\n",
    "df_movimentosNac = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/MovimentosNacionais.csv\")\n",
    "\n",
    "df_movimentosNac.createOrReplaceTempView(\"movimentos_nac\")\n",
    "\n",
    "df_qry_movimentosNac = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"trim(substring_index(MOVIMENTO, '-', 1)) AS codmovimento, \" + \n",
    "    \"trim(substring_index(MOVIMENTO, '-', -1)) AS descmovimento, \" + \n",
    "    \"CASE WHEN NATUREZA IS NULL THEN 'GERAL' ELSE NATUREZA END AS natureza, \" +\n",
    "    \"CASE WHEN FASE IS NULL THEN 'F0 - NÃO CLASSIFICADO' ELSE FASE END AS fase \" +\n",
    "    \"FROM movimentos_nac \" +\n",
    "    \"WHERE RELEVANCIA = 1\"\n",
    ")\n",
    "\n",
    "df_movimentos_join = df_movimentos \\\n",
    "    .join(df_qry_movimentosNac, df_movimentos[\"codigo\"] == df_qry_movimentosNac[\"codmovimento\"], \"left\")\n",
    "\n",
    "df_movimentos_join.createOrReplaceTempView(\"movimentos_com_fase\")\n",
    "\n",
    "df_qry_movimentos = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"codigo AS cod,\" + \n",
    "    \"descricao,\" + \n",
    "    \"natureza, \" +\n",
    "    \"fase, \" +\n",
    "    \"cod_pai AS codpai \" +    \n",
    "    \"FROM movimentos_com_fase \"\n",
    ")\n",
    "\n",
    "# df_qry_movimentos.write \\\n",
    "#     .mode(\"overwrite\") \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "#     .option(\"dbtable\", \"inovacnj.movimentocnj\") \\\n",
    "#     .save()\n",
    "\n",
    "print(\"tabela inovacnj.movimentocnj criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega do dataframe de serventias\n",
    "df_serventias = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/mpm_serventias.csv\")\n",
    "\n",
    "df_serventias.createOrReplaceTempView(\"serventias\")\n",
    "\n",
    "df_qry_serventias = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"SEQ_ORGAO AS cod, \" + \n",
    "    \"DSC_ORGAO AS descricao, \" + \n",
    "    \"SEQ_ORGAO_PAI AS codpai, \" + \n",
    "    \"TIP_ORGAO AS sigla_tipoj, \" + \n",
    "    \"DSC_TIP_ORGAO AS tipo_oj, \" + \n",
    "    \"DSC_CIDADE AS cidade, \" + \n",
    "    \"SIG_UF AS uf, \" + \n",
    "    \"COD_IBGE AS codibge, \" + \n",
    "    \"TIP_ESFERA_JUSTICA AS esfera \" + \n",
    "    \"FROM serventias \"\n",
    ")\n",
    "\n",
    "# df_qry_serventias.write \\\n",
    "#     .mode(\"overwrite\") \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "#     .option(\"dbtable\", \"inovacnj.orgao_julgador\") \\\n",
    "#     .save()\n",
    "\n",
    "print(\"tabela inovacnj.orgao_julgador criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# carregamento de todos os arquivos em um único DataFrame e geracao do CSV\n",
    "basedir = \"./base\"\n",
    "\n",
    "dirs_ramos_justica = [join(basedir, f) for f in os.listdir(basedir) if isdir(join(basedir, f))]\n",
    "\n",
    "is_first = True\n",
    "\n",
    "for dir_ramo_just in dirs_ramos_justica:\n",
    "    print(\"Iniciando carregamento do ramo de justica: \" + dir_ramo_just)\n",
    "    dirs_tribunais = [join(dir_ramo_just, f) for f in os.listdir(dir_ramo_just) if isdir(join(dir_ramo_just, f))]\n",
    "    \n",
    "    for dir_trib in dirs_tribunais:\n",
    "        print(\"Iniciando carregamento do tribunal: \" + dir_trib)\n",
    "        \n",
    "        arquivos = [join(dir_trib, f) for f in os.listdir(dir_trib) if isfile(join(dir_trib, f))]\n",
    "        \n",
    "        df_union_tribunal = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
    "        \n",
    "        for arq in arquivos:\n",
    "            if arq.endswith(\".DS_Store\") :\n",
    "                continue\n",
    "                \n",
    "            print(\"Carregando dataframe do arquivo: \" + arq)\n",
    "            df = spark.read.schema(schema).json(arq)\n",
    "            df_union_tribunal = df_union_tribunal.union(df)\n",
    "        \n",
    "        # Cria uma view temporaria para o dataframe\n",
    "        df_union_tribunal.createOrReplaceTempView(\"proc_movimentos\")\n",
    "        \n",
    "        # Query para formato em CSV\n",
    "        df_query_distinct = spark.sql(\n",
    "            \"SELECT DISTINCT \" + \n",
    "            \"siglaTribunal AS codtribunal, \" + \n",
    "            \"grau, \" +\n",
    "            \"millisinsercao, \" +\n",
    "\n",
    "            \"dadosBasicos.classeProcessual AS codclasse, \" +\n",
    "            \"dadosBasicos.codigoLocalidade AS codlocalidade, \" +\n",
    "            \"dadosBasicos.competencia, \" +\n",
    "            \"to_timestamp(dadosBasicos.dataAjuizamento, 'yyyyMMddHHmmss') AS dtajuizamento, \"\n",
    "            \"dadosBasicos.dscSistema AS descsistema, \" +\n",
    "            \"dadosBasicos.nivelSigilo AS nivelsigilo, \" +\n",
    "            \"dadosBasicos.numero AS npu, \" + \n",
    "            \"dadosBasicos.orgaoJulgador.codigoMunicipioIBGE AS oj_codibge, \" +\n",
    "            \"dadosBasicos.orgaoJulgador.codigoOrgao AS oj_cod, \" +\n",
    "            \"dadosBasicos.orgaoJulgador.instancia AS oj_instancia, \" +\n",
    "            \"dadosBasicos.orgaoJulgador.nomeOrgao AS oj_descricao, \" +\n",
    "            \"dadosBasicos.procEl AS tramitacao, \" +\n",
    "            \"dadosBasicos.tamanhoProcesso AS tamanhoprocesso, \" +\n",
    "            \"dadosBasicos.valorCausa AS valorcausa, \" +\n",
    "\n",
    "            \"exp_assunto.assunto.codigoNacional AS ass_cod, \" +\n",
    "            \"exp_assunto.assunto.principal AS ass_principal, \" + \n",
    "            \"exp_assunto.assunto.assuntoLocal.codigoAssunto AS ass_codlocal, \" +\n",
    "            \"exp_assunto.assunto.assuntoLocal.codigoPaiNacional AS ass_codpainacional, \" +\n",
    "            \"exp_assunto.assunto.assuntoLocal.descricao AS ass_desclocal, \" +\n",
    "\n",
    "            \"to_timestamp(exp_movimento.movimento.dataHora, 'yyyyMMddHHmmss') AS mov_dtmov, \" +\n",
    "            \"exp_movimento.movimento.movimentoLocal.codigoMovimento AS mov_codlocal, \" +\n",
    "            \"exp_movimento.movimento.movimentoLocal.codigoPaiNacional AS mov_codpainacional, \" +\n",
    "            \"exp_movimento.movimento.movimentoNacional.codigoNacional AS mov_cod, \" +\n",
    "            \"exp_movimento.movimento.nivelSigilo AS mov_nivelsigilo, \" +\n",
    "\n",
    "            \"exp_movimento.movimento.orgaoJulgador.codigoMunicipioIBGE as mov_oj_codibge, \" +\n",
    "            \"exp_movimento.movimento.orgaoJulgador.codigoOrgao as mov_oj_cod, \" +\n",
    "            \"exp_movimento.movimento.orgaoJulgador.instancia as mov_oj_instancia, \" +\n",
    "            \"exp_movimento.movimento.orgaoJulgador.nomeOrgao as mov_oj_descricao, \" +\n",
    "\n",
    "            \"exp_movimento.movimento.tipoDecisao as mov_tpdecisao, \" +\n",
    "            \"exp_movimento.movimento.tipoResponsavelMovimento as mov_tprespmov \" +\n",
    "\n",
    "            \"FROM proc_movimentos \" + \n",
    "            \"LATERAL VIEW explode(dadosBasicos.assunto) exp_assunto as assunto \" +\n",
    "            \"LATERAL VIEW explode(movimento) exp_movimento as movimento \" + \n",
    "            \"WHERE to_timestamp(dadosBasicos.dataAjuizamento, 'yyyyMMddHHmmss') >= to_timestamp('20000101000000', 'yyyyMMddHHmmss') \" + \n",
    "            \"AND exp_movimento.movimento.movimentoNacional.codigoNacional NOT IN(581, 85, 12270, 12271) \" + \n",
    "            \"AND size(proc_movimentos.movimento) > 0 \"\n",
    "            \"AND (proc_movimentos.movimento[0].movimentoNacional.codigoNacional IN (26, 12474) \" +\n",
    "            \"AND proc_movimentos.movimento[size(proc_movimentos.movimento) -1].movimentoNacional.codigoNacional IN (22, 246)) \"\n",
    "        )\n",
    "        \n",
    "        df_movimentos_join = df_query_distinct \\\n",
    "           .join(df_qry_movimentosNac, df_query_distinct[\"mov_cod\"] == df_qry_movimentosNac[\"codmovimento\"], \"left\") \\\n",
    "           .select( \\\n",
    "                col(\"codtribunal\"), col(\"grau\"), col(\"millisinsercao\"), col(\"codclasse\"), \\\n",
    "                col(\"codlocalidade\"), col(\"competencia\"), col(\"dtajuizamento\"), col(\"descsistema\"), \\\n",
    "                col(\"nivelsigilo\"), col(\"npu\"), col(\"oj_codibge\"), col(\"oj_cod\"), \\\n",
    "                col(\"oj_instancia\"), col(\"oj_descricao\"), col(\"tramitacao\"), col(\"tamanhoprocesso\"), \\\n",
    "                col(\"valorcausa\"), col(\"ass_cod\"), col(\"ass_principal\"), col(\"ass_codlocal\"), \\\n",
    "                col(\"ass_codpainacional\"), col(\"ass_desclocal\"), col(\"mov_dtmov\"), col(\"mov_codlocal\"), \\\n",
    "                col(\"mov_codpainacional\"), col(\"mov_cod\"), col(\"mov_nivelsigilo\"), col(\"mov_oj_codibge\"), \\\n",
    "                col(\"mov_oj_cod\"), col(\"mov_oj_instancia\"), col(\"mov_oj_descricao\"), col(\"mov_tpdecisao\"), \\\n",
    "                col(\"mov_tprespmov\"), col(\"natureza\"), col(\"fase\") \\\n",
    "        )\n",
    "        \n",
    "        df_query_distinctPd = df_movimentos_join.toPandas()\n",
    "        df_query_distinctPd.to_csv('./output/movimentos_tribunais.csv', mode='a', header=is_first, sep = \";\", index=False, chunksize=1000)\n",
    "        \n",
    "        if is_first == True:\n",
    "            is_first = False\n",
    "            df_movimentos_join.repartition(5).write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "                .option(\"dbtable\", \"inovacnj.fat_movimentos_te\") \\\n",
    "                .option(\"batchsize\", \"10000\") \\\n",
    "                .save()\n",
    "        else :\n",
    "            df_movimentos_join.repartition(5).write \\\n",
    "                .mode(\"append\") \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "                .option(\"dbtable\", \"inovacnj.fat_movimentos_te\") \\\n",
    "                .option(\"batchsize\", \"10000\") \\\n",
    "                .save()\n",
    "\n",
    "        print(\"Finalizando carregamento do tribunal: \" + dir_trib)\n",
    "        \n",
    "    print(\"Finalizando carregamento do ramo de justica: \" + dir_ramo_just)\n",
    "    \n",
    "print(\"Carregamento dos arquivos finalizado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega do dataframe com todos os movimentos dos processos\n",
    "df_proc_movimentos = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./output/movimentos.csv\")\n",
    "\n",
    "# Cria uma view temporaria para o dataframe\n",
    "df_proc_movimentos.createOrReplaceTempView(\"temp_proc_movimentos\")\n",
    "df_proc_movimentos.printSchema()\n",
    "df_proc_movimentos.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_modelo_pm_from_df(df, codtribunal, grau, natureza, codclasse):\n",
    "    \n",
    "    df.createOrReplaceTempView(\"temp_df_modelo_pm\")\n",
    "    \n",
    "    sql = \"SELECT npu, fase, to_timestamp(mov_dtmov, 'yyyy-MM-dd HH:mm:ss') as dtmov \"\n",
    "    sql+= \"FROM temp_df_modelo_pm \"\n",
    "    sql+= \"WHERE (1=1) \"\n",
    "    if codtribunal != None :\n",
    "        sql+= \"AND codtribunal = '\" + codtribunal + \"' \"\n",
    "    if grau != None :\n",
    "        sql+= \"AND grau = '\" + grau + \"' \"\n",
    "    if natureza != None :\n",
    "        sql+= \"AND natureza = '\" + natureza + \"' \"\n",
    "    if codclasse != None :\n",
    "        sql+= \"AND codclasse = \" + str(codclasse) + \" \"\n",
    "        \n",
    "    sql+= \"ORDER BY dtmov ASC \"\n",
    "    \n",
    "    df_logeventos = spark.sql(sql)\n",
    "    \n",
    "    df_logeventos_pd = df_logeventos.toPandas()\n",
    "    dataframe = pm4py.format_dataframe(df_logeventos_pd, case_id='npu', activity_key='fase', timestamp_key='dtmov')\n",
    "    eventLog = pm4py.convert_to_event_log(dataframe)\n",
    "\n",
    "    dfg = dfg_discovery.apply(eventLog, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "    gviz = dfg_visualization.apply(dfg, log=eventLog, variant=dfg_visualization.Variants.PERFORMANCE)\n",
    "    #dfg_visualization.view(gviz)\n",
    "    \n",
    "    return gviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_modelo_pm_from_db(codtribunal, grau, natureza, codclasse):\n",
    "    \n",
    "    sql = \"SELECT npu, fase, mov_dtmov \"\n",
    "    sql+= \"FROM inovacnj.fat_movimentos_tjpe \"\n",
    "    sql+= \"WHERE (1=1) \"\n",
    "    if codtribunal != None :\n",
    "        sql+= \"AND codtribunal = '\" + codtribunal + \"' \"\n",
    "    if grau != None :\n",
    "        sql+= \"AND grau = '\" + grau + \"' \"\n",
    "    if natureza != None :\n",
    "        sql+= \"AND natureza = '\" + natureza + \"' \"\n",
    "    if codclasse != None :\n",
    "        sql+= \"AND codclasse = \" + str(codclasse) + \" \"\n",
    "        \n",
    "    sql+= \"ORDER BY mov_dtmov ASC \"\n",
    "    \n",
    "    df_logeventos = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://postgres:5432/dbinovacnj\") \\\n",
    "        .option(\"query\", sql) \\\n",
    "        .option(\"user\", \"inovacnj\") \\\n",
    "        .option(\"password\", \"inovacnj@admin\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .load()\n",
    "    \n",
    "    df_logeventos_pd = df_logeventos.toPandas()\n",
    "    dataframe = pm4py.format_dataframe(df_logeventos_pd, case_id='npu', activity_key='fase', timestamp_key='mov_dtmov')\n",
    "    eventLog = pm4py.convert_to_event_log(dataframe)\n",
    "\n",
    "    dfg = dfg_discovery.apply(eventLog, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "    gviz = dfg_visualization.apply(dfg, log=eventLog, variant=dfg_visualization.Variants.PERFORMANCE)\n",
    "    #dfg_visualization.view(gviz)\n",
    "    \n",
    "    return gviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gviz = gerar_modelo_pm_from_db('TJPE', 'G1', 'GERAL', None)\n",
    "dfg_visualization.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import request\n",
    "from flask import send_file\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/download')\n",
    "def downloadFile ():\n",
    "    #For windows you need to use drive name [ex: F:/Example.pdf]\n",
    "    path = \"/Examples.pdf\"\n",
    "    return send_file(path, as_attachment=True)\n",
    "\n",
    "@app.route(\"/testeflask\")\n",
    "def teste():\n",
    "    param1 = request.args.get('teste')\n",
    "    response = \"Enviou param1 = \" + param1\n",
    "\n",
    "    return response\n",
    "\n",
    "app.run(host='0.0.0.0', port='8080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logeventos = spark.sql(\n",
    "    \"SELECT npu, fase, to_timestamp(mov_dtmov, 'yyyy-MM-dd HH:mm:ss') as dtmov \" + \n",
    "    \"FROM temp_proc_movimentos \" + \n",
    "    \"WHERE fase IS NOT NULL \" + \n",
    "    \"AND natureza = 'GERAL' \" + \n",
    "    \"ORDER BY mov_dtmov ASC\"\n",
    ")\n",
    "\n",
    "logMovimentosDfPD = df_logeventos.toPandas()\n",
    "dataframe = pm4py.format_dataframe(logMovimentosDfPD, case_id='npu', activity_key='fase', timestamp_key='dtmov')\n",
    "eventLog = pm4py.convert_to_event_log(dataframe)\n",
    "\n",
    "dfg = dfg_discovery.apply(eventLog, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "gviz = dfg_visualization.apply(dfg, log=eventLog, variant=dfg_visualization.Variants.PERFORMANCE)\n",
    "dfg_visualization.view(gviz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logeventos = spark.sql(\n",
    "    \"SELECT npu, fase, to_timestamp(mov_dtmov, 'yyyy-MM-dd HH:mm:ss') as dtmov \" + \n",
    "    \"FROM temp_proc_movimentos \" + \n",
    "    \"WHERE fase IS NOT NULL \" + \n",
    "    \"AND natureza = 'CRIMINAL' \" + \n",
    "    \"ORDER BY mov_dtmov ASC\"\n",
    ")\n",
    "\n",
    "logMovimentosDfPD = df_logeventos.toPandas()\n",
    "dataframe = pm4py.format_dataframe(logMovimentosDfPD, case_id='npu', activity_key='fase', timestamp_key='dtmov')\n",
    "eventLog = pm4py.convert_to_event_log(dataframe)\n",
    "\n",
    "dfg = dfg_discovery.apply(eventLog, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "gviz = dfg_visualization.apply(dfg, log=eventLog, variant=dfg_visualization.Variants.PERFORMANCE)\n",
    "dfg_visualization.view(gviz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logeventos = spark.sql(\n",
    "    \"SELECT npu, fase, to_timestamp(mov_dtmov, 'yyyy-MM-dd HH:mm:ss') as dtmov \" + \n",
    "    \"FROM temp_proc_movimentos \" + \n",
    "    \"WHERE fase IS NOT NULL \" + \n",
    "    \"AND natureza = 'CIVEL' \" + \n",
    "    \"ORDER BY mov_dtmov ASC\"\n",
    ")\n",
    "\n",
    "logMovimentosDfPD = df_logeventos.toPandas()\n",
    "dataframe = pm4py.format_dataframe(logMovimentosDfPD, case_id='npu', activity_key='fase', timestamp_key='dtmov')\n",
    "eventLog = pm4py.convert_to_event_log(dataframe)\n",
    "\n",
    "dfg = dfg_discovery.apply(eventLog, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "gviz = dfg_visualization.apply(dfg, log=eventLog, variant=dfg_visualization.Variants.PERFORMANCE)\n",
    "dfg_visualization.view(gviz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qry_test = spark.sql(\n",
    "    \"SELECT DISTINCT fase \" + \n",
    "    \"FROM proc_movimentos_join \" + \n",
    "    \"WHERE fase IS NOT NULL \" + \n",
    "    \"AND natureza = 'CIVEL' \"\n",
    ")\n",
    "\n",
    "df_qry_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando o carregamento de um arquivo com o schema\n",
    "df_test = spark.read.schema(schema).json(\"./base/justica_estadual/processos-tjap/processos-tjap_2.json\")\n",
    "# Cria uma view temporaria para o dataframe\n",
    "df_test.createOrReplaceTempView(\"test\")\n",
    "\n",
    "# Query para formato em CSV\n",
    "df_qry_test = spark.sql(\n",
    "    \"SELECT DISTINCT \" + \n",
    "    \n",
    "    \"dadosBasicos.numero, \" +\n",
    "    \"dadosBasicos.classeProcessual, \" +\n",
    "    \"to_timestamp(exp_movimento.movimento.dataHora, 'yyyyMMddHHmmss') as movimento_dataHora, \"\n",
    "    \"exp_movimento.movimento.movimentoNacional.codigoNacional as movimentoNacional_codigoNacional \"\n",
    "\n",
    "    \"FROM test \" + \n",
    "    \"LATERAL VIEW explode(movimento) exp_movimento as movimento \" + \n",
    "    \"WHERE dadosBasicos.dataAjuizamento >= 946684800000 AND \" + \n",
    "    \"exp_movimento.movimento.movimentoNacional.codigoNacional NOT IN(581, 85, 12270, 12271) \" +\n",
    "    \"AND size(test.movimento) > 0 AND \" + \n",
    "    \"(test.movimento[0].movimentoNacional.codigoNacional IN (26, 12474) \" +\n",
    "    \"AND test.movimento[size(test.movimento) -1].movimentoNacional.codigoNacional IN (22, 246)) \" +\n",
    "    \"ORDER BY movimento_dataHora ASC\"\n",
    ")\n",
    "\n",
    "df_qry_test = df_qry_test.join( \\\n",
    "    df_qry_movimentos, df_qry_test[\"movimentoNacional_codigoNacional\"] == df_qry_movimentos[\"cod\"], \"inner\")\n",
    "\n",
    "df_qry_test.createOrReplaceTempView(\"test_eventlog\")\n",
    "\n",
    "df_qry_test = spark.sql(\n",
    "    \"SELECT numero, fase, movimento_dataHora \" + \n",
    "    \"FROM test_eventlog \" + \n",
    "    \"WHERE fase IS NOT NULL \" + \n",
    "    \"AND natureza = 'CRIMINAL' \" + \n",
    "    \"ORDER BY movimento_dataHora ASC\"\n",
    ")\n",
    "\n",
    "df_qry_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logMovimentosDfPD = df_qry_test.toPandas()\n",
    "dataframe = pm4py.format_dataframe(logMovimentosDfPD, case_id='numero', activity_key='fase', timestamp_key='movimento_dataHora')\n",
    "eventLog = pm4py.convert_to_event_log(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for case_index, case in enumerate(eventLog):\n",
    "    print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "    for event_index, event in enumerate(case):\n",
    "        print(\"event index: %d  event activity: %s\" % (event_index, event[\"concept:name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualization\n",
    "\n",
    "dfg = dfg_discovery.apply(eventLog, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "gviz = dfg_visualization.apply(dfg, log=eventLog, variant=dfg_visualization.Variants.PERFORMANCE)\n",
    "dfg_visualization.view(gviz)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
